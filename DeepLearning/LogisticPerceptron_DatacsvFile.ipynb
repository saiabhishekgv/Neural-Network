{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding the Logistic Perceptron Algorithm\n",
    "\n",
    "Time to code! I have implemented the logistic perceptron algorithm to separate the following data (given in the file data.csv).\n",
    "\n",
    "Recall that the perceptron step works as follows. For a point with coordinates (p,q) , label y, and prediction given by the equation y = step(w1*x1 + w2*x2 + b). Then find cross-entropy and error function as follows:\n",
    "\n",
    "- If the point is correctly classified, do nothing.\n",
    "- If the point is classified negative, but it has a positive label, add αp,αq, and α to w1, w2 and b respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIGMOID FUNCTION :\n",
    "# The function should receive as input x,\n",
    "# and return 1/1+e^(-x) .\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Prime Function \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIGMOID PRIME FUNCTION :\n",
    "# The function should receive as input t,\n",
    "# and return sigmoid(t)*(1-sigmoid(t))\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction FUNCTION :\n",
    "# The function should receive as input Data X, weights W, and bias b\n",
    "# and return sigmoid(W*X+b)\n",
    "def prediction(X, W, b):\n",
    "    return sigmoid(np.matmul(X,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross function that takes as input two lists Y, P,\n",
    "# and returns the list of errors.\n",
    "def cross_entropy(Y, yHat):\n",
    "    return [-y[i]*np.log(y_hat[i]) - (1-y[i])*np.log(1-y_hat[i]) for i in range(len(y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Error function:\n",
    "# cross entropy divided by number of errors.\n",
    "def errorFunction(Y,yHat):\n",
    "    ev = cross_entropy(Y,yHat)\n",
    "    return sum(ev)/len(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Derivative of errors:\n",
    "# The result should be a list of three lists:\n",
    "# The first list should contain the gradient (partial derivatives) with respect to w1\n",
    "# The second list should contain the gradient (partial derivatives) with respect to w2\n",
    "# The third list should contain the gradient (partial derivatives) with respect to b\n",
    "def dErrors(X, y, y_hat):\n",
    "    DErrorsDx1 = [X[i][0]*(y[i]-y_hat[i]) for i in range(len(y))]\n",
    "    DErrorsDx2 = [X[i][1]*(y[i]-y_hat[i]) for i in range(len(y))]\n",
    "    DErrorsDb = [y[i]-y_hat[i] for i in range(len(y))]\n",
    "    return DErrorsDx1, DErrorsDx2, DErrorsDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b.\n",
    "# It should calculate the prediction, the gradients, and use them to\n",
    "# update the weights and bias W, b. Then return W and b.\n",
    "# The error e will be calculated and returned for you, for plotting purposes.\n",
    "def gradientDescentStep(X, y, W, b, learn_rate = 0.01):\n",
    "    yHat = prediction(X,W,b)\n",
    "    errors = cross_entropy(y, yHat)\n",
    "    derivErrors = dErrors(X, y, yHat)\n",
    "    W[0] += sum(derivErrors[0])*learn_rate\n",
    "    W[1] += sum(derivErrors[1])*learn_rate\n",
    "    b += sum(derivErrors[2])*learn_rate\n",
    "    return W, b, sum(errors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainLR(X, y, learn_rate = 0.01, num_epochs = 100):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    # Initialize the weights randomly\n",
    "    W = np.array(np.random.rand(2,1))*2 -1\n",
    "    b = np.random.rand(1)[0]*2 - 1\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    errors = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the gradient descent step.\n",
    "        W, b, error = gradientDescentStep(X, y, W, b, learn_rate)\n",
    "        errors.append(error)\n",
    "    boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
