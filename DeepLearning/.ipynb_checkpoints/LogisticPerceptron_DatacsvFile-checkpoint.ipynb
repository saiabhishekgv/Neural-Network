{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding the Logistic Perceptron Algorithm\n",
    "\n",
    "Time to code! I have implemented the logistic perceptron algorithm to separate the following data (given in the file data.csv).\n",
    "\n",
    "Recall that the perceptron step works as follows. For a point with coordinates (p,q) , label y, and prediction given by the equation y = step(w1*x1 + w2*x2 + b). Then find cross-entropy and error function as follows:\n",
    "\n",
    "- If the point is correctly classified, do nothing.\n",
    "- If the point is classified negative, but it has a positive label, add αp,αq, and α to w1, w2 and b respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, yHat):\n",
    "    sum = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        sum += Y[i]*np.log(yHat[i]) + ((1-Y[i])*np.log(1-yHat[i]))\n",
    "    return -sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP FUNCTION :\n",
    "# The function should receive as inputs t,\n",
    "# and return 1 if t>=0 or 0.\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function should receive as inputs data X, weights W and the bias b\n",
    "# and return 1 if (WX+b)>=0 or 0.\n",
    "def prediction(X, W, b):\n",
    "    # if you want to use step function as activation function\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "    # if you want to use softmax function as activation function\n",
    "    #return softmax(np.matmul(X,W)+b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    error = 0.0 \n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i],W,b)\n",
    "# Calucalte error in 2 ways :\n",
    "# 1st way\n",
    "#         if y_hat == 1:\n",
    "#             error += -np.log(y_hat)\n",
    "#         elif y_hat == 0:\n",
    "#             error += -np.log(1-y_hat)\n",
    "# 2nd way\n",
    "        error += -(1-y[i])*(log(1-y_hat))- (y[i]* log(y_hat))\n",
    "    error = (1/len(X))*error\n",
    "    return error,W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainLogisticPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    error = sys.maxint\n",
    "    while error>0.01:\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        error,W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "        if(num_epoches==25):\n",
    "            break\n",
    "    return boundary_lines"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
